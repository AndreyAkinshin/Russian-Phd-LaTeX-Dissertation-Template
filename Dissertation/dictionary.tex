\chapter*{Список сокращений и условных обозначений} % Заголовок
\addcontentsline{toc}{chapter}{Список сокращений и условных обозначений} % Добавляем его в оглавление

\noindent\textbf{JC (Jaynes-Cummings model)} --- модель Джейнса-Каммингса.\\
\noindent\textbf{TC (Tavis-Cummings model)} --- модель Тависа-Каммингса.\\
\noindent\textbf{JCH (Jaynes-Cummings-Hubbard model)} --- модель Джейнса-Каммингса-Хаббарда.\\
\noindent\textbf{TCH (Tavis-Cummings-Hubbard model)} --- модель Тависа-Каммингса-Хаббарда.\\
\noindent\textbf{RWA (rotating-wave approximation)} --- приближение вращающейся волны, при котором слагаемые
$a^{+}\s^{+}$, $a\s$ гамильтониана моделей JC/JCH/TC/TCH, не сохраняющие энергию, можно игнорировать. В картине взаимодействия они быстро осциллируют, что и делает их вклад незначительным.\\
\noindent\textbf{GPU (graphics processing unit)} --- графический процессор, который предназначен для ускорения рендеринга графики и параллельных вычислений. GPU содержат от нескольких сотен до нескольких тысяч вычислительных ядер. Благодаря особенностям своей архитектуры и возможностям параллельной обработки данных GPU используют для систем искусственного интеллекта, машинного обучения и высокопроизводительных вычислений.\\
\noindent\textbf{SMP (symmetric multiprocessing}, или \textbf{shared-memory multiprocessing)} --- архитектура многопроцессорных компьютеров, в которой два или более одинаковых процессора сравнимой производительности подключаются единообразно к общей памяти и имеют равный доступ ко всем ресурсам вычислительной системы (в силу чего, система и называется симметричной).\\
\noindent\textbf{MPP (massive parallel processing, массивно-параллельная архитектура)} --- класс архитектур параллельных вычислительных систем. Особенность архитектуры состоит в том, что оперативная память физически разделена между процессорами. Главным преимуществом систем с разделенной памятью является их хорошая масштабируемость.\\
\noindent\textbf{MPI (message passing interface, интерфейс передачи сообщений)} --- программный интерфейс передачи информации для обмена сообщениями между процессами, синхронизации выполнения задач, а также управления потоками данных в параллельных вычислениях. Является наиболее распространенным стандартом для построения высокопроизводительных программ для кластеров и суперкомпьютеров.
